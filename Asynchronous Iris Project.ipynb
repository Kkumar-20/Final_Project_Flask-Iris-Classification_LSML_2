{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"img/celery-logo.png\">\n",
    "https://docs.celeryproject.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celery\n",
    "\n",
    "Celery is a library for building distributed message queue applications. It allows you to define handler functions for specific messages in queues and provides a convenient interface for creating such messages and saving the results.\n",
    "\n",
    "Celery does not know how to work on its own - it needs the queuing system itself to work. For these purposes, we will use Redis, since Redis can work both as a distributed message queue (message broker) and as a database for storing results. In the current environment, Redis is already running and processing requests on port 6379.\n",
    "\n",
    "There are also two scripts for the background launch of our service components. `launch-server.sh` works the same as in the previous lab and launches the Flask application. `start-worker.sh` works in a similar way. This script assumes that there is a `server.py` script and a `celery_app` variable has been created in which the main celery application is written. If the conditions are met, the command starts a worker in the background to monitor the queue.\n",
    "\n",
    "IMPORTANT - the server writes its logs to `log.txt`, and the celery handler to `log-worker.txt`. If something breaks, then the first place to look is in these files. Restarting the server or handler can also solve the problem - sometimes they simply do not have time to restart and therefore the request to them falls with an error.\n",
    "\n",
    "Let's try to create at first just a set of tasks and start them in manual mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server.py\n",
    "from celery import Celery\n",
    "import time\n",
    "\n",
    "celery_app = Celery('server', backend='redis://localhost', broker='redis://localhost')  # both database and broker are redis\n",
    "\n",
    "@celery_app.task\n",
    "def add(x, y):\n",
    "    time.sleep(7.0)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start the worker with our handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! start-worker.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a running worker. We can import tasks and send several tasks to the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from server import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = add.delay(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: 7dd50c73-1505-4ad5-837b-d674e75265e5>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7dd50c73-1505-4ad5-837b-d674e75265e5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! After a while, our task was counted and we got its result.\n",
    "\n",
    "In order to get the result, it is enough to know only its identifier. Let's try to get the result knowing only the identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celery.result import AsyncResult\n",
    "from server import celery_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72e9bde7-f276-4ab9-8ccb-0e0aeb45af65\n"
     ]
    }
   ],
   "source": [
    "task_id = add.delay(12, 13).id\n",
    "print(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "r = AsyncResult(task_id, app=celery_app)\n",
    "print(r.ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect the web serverÂ¶\n",
    "This knowledge should be enough for us to start the service together with the web server. The web server, receiving a request from the user, will create a new task and send it to the queue, returning the task ID to the user.\n",
    "\n",
    "Then the user can come back and ask the web server for the status of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server.py\n",
    "from celery import Celery\n",
    "from celery.result import AsyncResult\n",
    "import time\n",
    "from flask import Flask, request\n",
    "import json\n",
    "\n",
    "\n",
    "celery_app = Celery('server', backend='redis://localhost', broker='redis://localhost')\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@celery_app.task\n",
    "def add(numbers):\n",
    "    time.sleep(7.0)\n",
    "    result = 0\n",
    "    for n in numbers:\n",
    "        result += n\n",
    "    return result\n",
    "\n",
    "\n",
    "@app.route('/sum', methods=[\"GET\", \"POST\"])\n",
    "def sum_handler():\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json(force=True)\n",
    "        numbers = data['numbers']\n",
    "        \n",
    "        task = add.delay(numbers) \n",
    "            \n",
    "        response = {\n",
    "            \"task_id\": task.id\n",
    "        }\n",
    "        return json.dumps(response)\n",
    "    \n",
    "    \n",
    "@app.route('/sum/<task_id>')\n",
    "def sum_check_handler(task_id):\n",
    "    task = AsyncResult(task_id, app=celery_app)\n",
    "    if task.ready():\n",
    "        response = {\n",
    "            \"status\": \"DONE\",\n",
    "            \"result\": task.result\n",
    "        }\n",
    "    else:\n",
    "        response = {\n",
    "            \"status\": \"IN_PROGRESS\"\n",
    "        }\n",
    "    return json.dumps(response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run('0.0.0.0', 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! start-worker.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! launch-server.sh server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function for the client who expects the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Classification models\n",
    "Loading more complex models is practically no different from what we did in the previous lab. Let's try to reproduce exactly the same service, but now using a message queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting freqmeter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile freqmeter.py\n",
    "\n",
    "import re\n",
    "\n",
    "class FrequencyMeter:\n",
    "    def __init__(self):\n",
    "        self._counter = {}\n",
    "        self._word_pattern = re.compile(r\"[a-z]+\")\n",
    "        \n",
    "    def fit(self, data):\n",
    "        for match in self._word_pattern.finditer(data.lower()):\n",
    "            word = match.group(0)\n",
    "            if word in self._counter:\n",
    "                self._counter[word] += 1\n",
    "            else:\n",
    "                self._counter[word] = 1\n",
    "    \n",
    "    def compute(self, word):\n",
    "        if word not in self._counter:\n",
    "            return 0\n",
    "        return self._counter[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freqmeter import FrequencyMeter\n",
    "import pickle\n",
    "\n",
    "fmeter = FrequencyMeter()\n",
    "\n",
    "with open('iris.csv') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "fmeter.fit(data)\n",
    "\n",
    "raw_data = pickle.dumps(fmeter)\n",
    "\n",
    "with open('fmeter-model.pickle', 'wb') as f:\n",
    "    f.write(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server.py\n",
    "from celery import Celery\n",
    "from celery.result import AsyncResult\n",
    "import time\n",
    "from flask import Flask, request\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "celery_app = Celery('server', backend='redis://localhost', broker='redis://localhost')\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "def load_model(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        model = pickle.loads(raw_data)\n",
    "    return model\n",
    "\n",
    "model = load_model('fmeter-model.pickle')\n",
    "\n",
    "\n",
    "@celery_app.task\n",
    "def freq(sentence):\n",
    "    result = {}\n",
    "    word_pattern = re.compile(r\"[a-z]+\")\n",
    "    for match in word_pattern.finditer(sentence.lower()):\n",
    "        word = match.group(0)\n",
    "        result[word] = model.compute(word)\n",
    "    return result\n",
    "\n",
    "\n",
    "@app.route('/frequency', methods=[\"GET\", \"POST\"])\n",
    "def frequency_handler():\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json(force=True)\n",
    "        sentence = data['sentence']\n",
    "        \n",
    "        task = freq.delay(sentence) \n",
    "            \n",
    "        response = {\n",
    "            \"task_id\": task.id\n",
    "        }\n",
    "        return json.dumps(response)\n",
    "    \n",
    "    \n",
    "@app.route('/frequency/<task_id>')\n",
    "def frequency_check_handler(task_id):\n",
    "    task = AsyncResult(task_id, app=celery_app)\n",
    "    if task.ready():\n",
    "        response = {\n",
    "            \"status\": \"DONE\",\n",
    "            \"result\": task.result\n",
    "        }\n",
    "    else:\n",
    "        response = {\n",
    "            \"status\": \"IN_PROGRESS\"\n",
    "        }\n",
    "    return json.dumps(response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run('0.0.0.0', 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! start-worker.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! launch-server.sh server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def calc(sentence):\n",
    "    response = requests.post(\"http://localhost:8000/frequency\", json={'sentence': sentence})\n",
    "    task_id = response.json()['task_id']\n",
    "    print(\"Task {}\".format(task_id))\n",
    "    status = \"IN_PROGRESS\"\n",
    "    while status != \"DONE\":\n",
    "        time.sleep(2.0)\n",
    "        r = requests.get('http://localhost:8000/frequency/{}'.format(task_id))\n",
    "        status = r.json()['status']\n",
    "        print('Status - {}'.format(status))\n",
    "    return r.json()['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Iris Data wirh variety of flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 03c90830-40f0-42e7-8882-bfe7a4ceeeb5\n",
      "Status - DONE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'setosa': 50}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc(\"Setosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2e993655-0d95-46c3-be7f-66904fd98409\n",
      "Status - DONE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'versicolor': 50}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc(\"Versicolor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
