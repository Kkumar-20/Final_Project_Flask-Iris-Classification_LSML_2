{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP38QZmetiOF"
   },
   "source": [
    "## MLflow architecture\n",
    "\n",
    "### MLflow Components and Their Tasks\n",
    "\n",
    " - MLflow Project - creating an environment for experiments, grouping experiments.\n",
    " - MLflow Tracking - fixing parameters and quality metrics of experiments.\n",
    " - MLflow Models - preparing a version of the model for distribution.\n",
    " - MLflow Registry - centralized repository of models and layout in operation.\n",
    "\n",
    "#### MLflow Projects\n",
    "\n",
    "- Setting up the environment:\n",
    "- programming languages\n",
    "- package manager (e.g. conda)\n",
    "- dependency (xgboost libraries, scikit-learn, ...)\n",
    "\n",
    "- Description of the environment (Infrastructure as code):\n",
    "- various OS\n",
    "- local environment\n",
    "- cloud services\n",
    "\n",
    "#### MLflow Tracking\n",
    "\n",
    "Fixes everything related to the launch of the model:\n",
    " - Datasets (for training and testing)\n",
    " - Sets of parameters (e.g. number of trees, layers, L1 / L2)\n",
    " - Values of quality metrics\n",
    " - Speed of work and other technical metrics.\n",
    "\n",
    "#### MLflow Models and Client\n",
    "\n",
    "- Serializes model artifacts as needed additional development\n",
    "- Information about which model is used on which environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BEePQncutiOG"
   },
   "source": [
    "## 1. Working with a project and running an experiment\n",
    "\n",
    "A project is a folder with files associated with this project:\n",
    "  - File with MLProject metadata (YAML format) and also include files (for example, conda.yaml)\n",
    "  - Files with code for running experiments (for example, in Python)\n",
    "\n",
    "To create a project, it is enough to describe the correct MLProject file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNTCeR9mtiOG"
   },
   "source": [
    "### Example of creating a project\n",
    "\n",
    "The `MLproject` project file specifies that the model is trained in the` conda` environment, and is used by `scikit-learn` as the ML library (specified in` conda.yaml`). The training of the model itself is described in the file `train.py`, the necessary data preparation is also described there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sG2RbzP8tiOH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MLproject\n"
     ]
    }
   ],
   "source": [
    "%%writefile MLproject\n",
    "name: Final_Project\n",
    "\n",
    "conda_env: conda.yaml\n",
    "\n",
    "entry_points:\n",
    "      main:\n",
    "        parameters:\n",
    "            SepalLengthCm: {type: float, default: 4.6}\n",
    "            SepalWidthCm: {type: float, default: 3.6}\n",
    "            PetalLengthCm: {type: float, default: 1.0}\n",
    "            PetalWidthCm: {type: float, default: 0.2}\n",
    "        command: \"python app.py {SepalLengthCm} {SepalWidthCm} {PetalLengthCm} {PetalWidthCm}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLbCF8xMtiOL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda.yaml\n",
    "name: Final_Project\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - numpy>=1.14.3\n",
    "  - pandas>=1.0.0\n",
    "  - scikit-learn=0.19.1\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9sT2UELtiOO"
   },
   "source": [
    "#### Preparing data for the experiment\n",
    "\n",
    "The following code imports the modules necessary for work, loads the data from the `wine-quality.csv` file and splits them into test and validation selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71EbeHxctiOO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "MLFLOW_SERVER_URL = 'http://127.0.0.1:5000'\n",
    "\n",
    "import array\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "data = pd.read_csv(\"Dataset/iris.csv\")\n",
    "\n",
    "import sklearn\n",
    "encoder = sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "y = np.array(data[\"variety\"])\n",
    "y = y.reshape(-1,1)\n",
    "encoder.fit(y)\n",
    "data[\"variety\"] = encoder.transform(y).toarray()\n",
    "\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "train_x = train.drop([\"variety\"], axis=1)\n",
    "test_x = test.drop([\"variety\"], axis=1)\n",
    "train_y = train[[\"variety\"]]\n",
    "test_y = test[[\"variety\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYpEklGEtiON"
   },
   "source": [
    "### Create and run an experiment\n",
    "\n",
    "The experiment code itself does not depend on MLflow, you can use the ready-made code.\n",
    "\n",
    "To fix the launch parameters and metrics of the model, you need to start training within the experiment and project.\n",
    "\n",
    "`tracking_url` - the address of the raised` mlflow` server, which will be used to store experiments. The web interface is also available at this address for viewing the launch results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wI_qE7zNtiOR"
   },
   "source": [
    "#### Running the experiment\n",
    "\n",
    "To run the experiment, you need to execute the model creation code inside the MLflow launch context and store the parameters and resulting metrics in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drfGPepntiOR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 0.25753089436149107\n",
      "  MAE: 0.23424782687663875\n",
      "  R2: 0.7149726152407471\n"
     ]
    }
   ],
   "source": [
    "# connect to the server\n",
    "import os\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'name'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'pass'\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER_URL)\n",
    "\n",
    "experiment_name = 'Final_Project'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# run the experiment\n",
    "with mlflow.start_run():\n",
    "    alpha = 0.5\n",
    "    l1_ratio = 0.5\n",
    "\n",
    "    # model\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    # metrics\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, predicted_qualities))\n",
    "    mae = mean_absolute_error(test_y, predicted_qualities)\n",
    "    r2 = r2_score(test_y, predicted_qualities)\n",
    "\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # save the metric values for the experiment\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sIYTUGvStiOU"
   },
   "source": [
    "## 2. Preparing the model for distribution\n",
    "\n",
    "The launch of a successful experiment can be prepared for commissioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50MQhVLYtiOU"
   },
   "source": [
    "### Review the conducted experiments and select the candidate for deployment\n",
    "\n",
    "To get information about running experiments, you need to create a client `mlflow.tracking.MlflowClient`, then select the experiment you want and select the desired experiment start.\n",
    "\n",
    "The code below takes the last run of the experiment from the list of all runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8dYq2YjtiOV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='./mlruns/3', experiment_id='3', lifecycle_stage='active', name='Final_Project', tags={}>\n",
      "<RunInfo: artifact_uri='./mlruns/3/b5735d1ced244550a62255ff03b52961/artifacts', end_time=1652018151889, experiment_id='3', lifecycle_stage='active', run_id='b5735d1ced244550a62255ff03b52961', run_uuid='b5735d1ced244550a62255ff03b52961', start_time=1652018151852, status='FAILED', user_id='kanishkkumar'>\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URL)\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "run_info = client.list_run_infos(experiment.experiment_id)[-1]\n",
    "\n",
    "print(experiment)\n",
    "print(run_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZvbsRvmtiOY"
   },
   "source": [
    "###  A Model in the MLflow Model Client\n",
    "\n",
    "Model Client is also available in the web interface. To do this, select a model on the experiments page\n",
    "\n",
    "Below is a code that performs a similar action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Social NLP Experiments\n",
      "Experiment_id: 1\n",
      "Artifact Location: ./mlruns/1\n",
      "Tags: {'nlp.framework': 'Spark NLP'}\n",
      "Lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create an experiment with a name that is unique and case sensitive.\n",
    "client = MlflowClient()\n",
    "experiment_id = client.create_experiment(\"Social NLP Experiments\")\n",
    "client.set_experiment_tag(experiment_id, \"nlp.framework\", \"Spark NLP\")\n",
    "\n",
    "# Fetch experiment metadata information\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2EsnX4etiOc"
   },
   "source": [
    "## 3. Deployment of the model and testing the server\n",
    "\n",
    "To use the model in a specific environment, you need to transfer the client model to the desired environment. This operation the client model in the desired environment, does not start the web server.\n",
    "\n",
    "### Deployment of the model in test and production environments\n",
    "\n",
    "Terminology used in MLflow Model Client:\n",
    "\n",
    "  - Experiment - test experiment\n",
    "  - Production - operational experiment\n",
    "  - Location - experiment location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: SocialMediaTextAnalyzer\n",
      "Experiment_id: 5\n",
      "Artifact Location: ./mlruns/5\n",
      "Tags: {'nlp.framework': 'Spark NLP'}\n",
      "Lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create an experiment with a name that is unique and case sensitive.\n",
    "client = MlflowClient()\n",
    "experiment_id = client.create_experiment(\"SocialMediaTextAnalyzer\")\n",
    "client.set_experiment_tag(experiment_id, \"nlp.framework\", \"Spark NLP\")\n",
    "\n",
    "# Fetch experiment metadata information\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    " \n",
    "# The default path where the MLflow autologging function stores the model\n",
    "artifact_path = \"model\"\n",
    "model_uri = \"runs:/{run_id}/{artifact_path}\".format(run_id=experiment_, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sHABAzotiOf"
   },
   "source": [
    "To use the model, you need to start a web server, pass it the name of the model and environment, as well as the port (in the example, it runs on port 8080) as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBCKeROStiOg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('MLFLOW_TRACKING_URI=http://127.0.0.1:5000/ mlflow models serve -m \"models:/sk-learn-new-model/Staging\" -p 5005 --no-conda &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Y6gZTi2tiOi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: <!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <title>Prediction</title>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
      "    <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\" integrity=\"sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\" crossorigin=\"anonymous\">\n",
      "   \n",
      "</head>\n",
      "<body>\n",
      "<div class=\"container\">\n",
      "    <div class=\"row\">\n",
      "        <div class=\"span4\"></div>\n",
      "        <div class=\"span4\">\n",
      "\n",
      "<h1>FLASK APP RUNNING</h1>\n",
      "<h2>Please enter your flower measurements below:</h2>\n",
      "<form method=\"POST\">\n",
      "    \n",
      "    <input id=\"csrf_token\" name=\"csrf_token\" type=\"hidden\" value=\"ImU0ZjE0YjY4NTNjZWI2MDdjZmJhNjFlNDliZmE4ZjAwODdjOGY1YmYi.Ynfryg.dIV-J3kedB-kYBAp1Jz7bV77MTU\">\n",
      "    <table class=\"table\">\n",
      "        <tr>\n",
      "        <th>Attribute</th>\n",
      "        <th>Value</th>\n",
      "    </tr>\n",
      "        <tr>\n",
      "            <td> <label for=\"SepalLengthCm\">Sepal Length</label></td>\n",
      "            <td> <input id=\"SepalLengthCm\" name=\"SepalLengthCm\" type=\"text\" value=\"\"></td>\n",
      "        </tr>\n",
      "\n",
      "    <tr>\n",
      "        <td><label for=\"SepalWidthCm\">Sepal Width</label></td>\n",
      "        <td> <input id=\"SepalWidthCm\" name=\"SepalWidthCm\" type=\"text\" value=\"\"></td>\n",
      "    </tr>\n",
      "\n",
      "    <tr>\n",
      "        <td><label for=\"PetalLengthCm\">Petal Length</label></td>\n",
      "        <td><input id=\"PetalLengthCm\" name=\"PetalLengthCm\" type=\"text\" value=\"\"></td>\n",
      "    </tr>\n",
      "\n",
      "    <tr>\n",
      "        <td><label for=\"PetalWidthCm\">Petal With</label></td>\n",
      "        <td><input id=\"PetalWidthCm\" name=\"PetalWidthCm\" type=\"text\" value=\"\"></td>\n",
      "    </tr>\n",
      "    </table>\n",
      "    <input id=\"submit\" name=\"submit\" type=\"submit\" value=\"Predict\">\n",
      "</form>\n",
      "</div>\n",
      "<div class=\"span4\"></div>\n",
      "\n",
      "\n",
      "</div>\n",
      "</div>\n",
      "<script src=\"https://code.jquery.com/jquery-3.3.1.slim.min.js\" integrity=\"sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\" crossorigin=\"anonymous\"></script>\n",
      "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\" integrity=\"sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1\" crossorigin=\"anonymous\"></script>\n",
      "<script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" crossorigin=\"anonymous\"></script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = f'http://127.0.0.1:8080'\n",
    "\n",
    "http_data = test_x[:10].to_json(orient='split')\n",
    "response = requests.post(url=url, headers={'Content-Type': 'application/json'}, data=http_data)\n",
    "\n",
    "print(f'Predictions: {response.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HTML Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanking You"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mlflow-e2e.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
